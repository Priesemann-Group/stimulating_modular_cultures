{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Experimental Data\n",
    "\n",
    "Most of the analysis is the same for experiments and simulations.\n",
    "The comparison across conditions is implemented in a stand-alone script `ana/process_conditions.py`, that can be run from a terminal and takes a the following arguments:\n",
    "* `-i` the base path to the folder where the data is stored.\n",
    "* `-t` the type of experiment (yields the right subfolders and file names):\n",
    "    - `exp` for main results, from optogenetic stimulation and different topologies\n",
    "    - `exp_chemical` for the experiments with KCl\n",
    "    - `exp_bic` for the experiments with Bicuculline\n",
    "    - `sim_partial` for simulations where only part of the system was targeted.\n",
    "* `-o` where to store the output path.\n",
    "\n",
    "To create the preprocessed data, navigate to the base directory and run:\n",
    "```bash\n",
    "python ./ana/process_conditions.py -t exp -i ./dat/experiments/raw/  -o ./dat/experiments/processed/\n",
    "python ./ana/process_conditions.py -t exp_chemical -i ./dat/experiments/raw/ -o ./dat/experiments/processed/\n",
    "python ./ana/process_conditions.py -t exp_bic -i ./dat/experiments/raw/ -o ./dat/experiments/processed/\n",
    "```\n",
    "\n",
    "\n",
    "This should yield the following files:\n",
    "```bash\n",
    ">>> tree -L 2 --dirsfirst ./dat/experiments/processed/\n",
    "dat/experiments/processed/\n",
    "├── 1b\n",
    "│   ├── 210315_A\n",
    "│   ├── 210315_C\n",
    "│   ├── 210405_C\n",
    "│   ├── 210406_B\n",
    "│   ├── 210406_C\n",
    "│   ├── 210719_B\n",
    "│   ├── 210719_C\n",
    "│   └── 210726_B\n",
    "├── 3b\n",
    "│   ├── 210316_A\n",
    "│   ...\n",
    "├── Bicuculline_1b\n",
    "│   ├── 210907_1bB\n",
    "│   ...\n",
    "├── KCl_1b\n",
    "│   ├── 210420_C\n",
    "│   ...\n",
    "├── merged\n",
    "│   ├── 210401_A\n",
    "│   ...\n",
    "├── 1b.hdf5\n",
    "├── 3b.hdf5\n",
    "├── Bicuculline_1b.hdf5\n",
    "├── KCl_1b.hdf5\n",
    "└── merged.hdf5\n",
    "```\n",
    "\n",
    "where the `*.hdf5` files contain the preprocessed data and the folders for each experiment have some additional info. See also `save_analysed_h5f` in `ana/process_conditions.py`.\n",
    "\n",
    "Low-level plotting functions are contained in `ana/plot_helper.py` and\n",
    "the higher-level wrappers as well as further analysis are in `ana/paper_plots.py`.\n",
    "In particular, most contend of this notebook can also be found in `paper_plots.py/fig_x()`\n",
    "\n",
    "Experiments are depicted in Figures 1 and 2, and in the Supplemental Material.\n",
    "For fine-grained control, we produced every figure panel as a stand-alone and combined them later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The autoreload extension allows you to tweak the code in the imported modules (`pp`)\n",
    "# and rerun cells to reflect the changes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext ipy_dict_hierarchy\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../ana/\")\n",
    "\n",
    "import paper_plots as pp\n",
    "# reduce the printed output, we have lots of details on the INFO level.\n",
    "pp.log.setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pp.fig_1.__doc__)\n",
    "pp.fig_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pp.fig_2.__doc__)\n",
    "pp.fig_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplemental Material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "python ./ana/process_conditions.py -t sim_partial -i ./dat/simulations/lif/raw/ -o ./dat/simulations/lif/processed/partial/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pp.sm_exp_trialwise_observables.__doc__)\n",
    "pp.sm_exp_trialwise_observables(prefix=f\"{pp.p_fo}/exp_layouts_sticks\")\n",
    "\n",
    "# the test results are logged at INFO level and\n",
    "# returned as a pandas dataframe.\n",
    "# pp.log.setLevel(\"INFO\")\n",
    "print(\"p-values: two-sided, paired-sample t-test:\")\n",
    "pp.nhst_pairwise_for_trials(\n",
    "    observables=[\n",
    "        # \"Mean Correlation\",\n",
    "        # \"Mean IBI\",\n",
    "        \"Mean Fraction\", # this is the event size\n",
    "        \"Functional Complexity\",\n",
    "        # \"Mean Core delays\",\n",
    "        # \"Mean Rate\",\n",
    "        # \"Median IBI\",\n",
    "        # \"Median Core delays\",\n",
    "    ],\n",
    "    layouts=[\"1b\", \"3b\", \"merged\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian import best, best_paired, probability_of_direction\n",
    "from paper_plots import p_exp, p_fo, p_sim, _p_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem = pp.load_pd_hdf5(f\"{p_exp}/processed/KCl_1b.hdf5\")\n",
    "opto = pp.load_pd_hdf5(f\"{p_exp}/processed/1b.hdf5\")\n",
    "\n",
    "dfs = dict()\n",
    "dfs[\"exp\"] = opto[\"trials\"].query(\"`Condition` in ['pre', 'stim']\")\n",
    "dfs[\"exp_chemical\"] = chem[\"trials\"]\n",
    "\n",
    "df = dfs[\"exp\"]\n",
    "df_on = df.query(\"`Stimulation` == 'On'\")\n",
    "df_off = df.query(\"`Stimulation` == 'Off'\")\n",
    "trials = df_on.Trial.unique()\n",
    "print(f\"trials are consistent: {np.all([t in df_off.Trial.unique() for t in trials])}\")\n",
    "\n",
    "obs = \"Functional Complexity\"\n",
    "\n",
    "# build the pairs\n",
    "y1 = []\n",
    "y2 = []\n",
    "for t in trials:\n",
    "    val1 = df_off.query(f\"`Trial` == '{t}'\")[obs].values\n",
    "    assert len(val1) == 1\n",
    "    val2 = df_on.query(f\"`Trial` == '{t}'\")[obs].values\n",
    "    assert len(val2) == 1\n",
    "\n",
    "    y1.append(val1[0])\n",
    "    y2.append(val2[0])\n",
    "\n",
    "# trace = best(y1, y2, n1=\"pre\", n2=\"stim\")\n",
    "diff_trace = best_paired(y1, y2, draws=4000, chains=4)\n",
    "diff_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import arviz as az\n",
    "# import bokeh\n",
    "# bokeh.io.output_notebook() \n",
    "\n",
    "# az.plot_posterior(\n",
    "#     trace,\n",
    "#     var_names=[\"diff_of_means\", \"diff_of_stds\", \"effect_size\"],\n",
    "#     # reference 0 for no effect\n",
    "#     ref_val=0,\n",
    "#     backend=\"bokeh\",\n",
    "# );\n",
    "\n",
    "az.plot_posterior(\n",
    "    diff_trace,\n",
    "    var_names=[\"mean_of_diffs\", \"std_of_diffs\", \"effect_size\"],\n",
    "    # reference 0 for no effect\n",
    "    ref_val=0,\n",
    "    backend=\"bokeh\",\n",
    ");\n",
    "diff_trace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('modular_cultures')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6dc1a597d6faf0fa9edd83aa5bb0712fc8986db7d9fb6d2b84cf56a8bf3b013"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
